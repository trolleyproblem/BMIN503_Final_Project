---
title: "Deep Learning for Spirometry"
subtitle: "BMIN503/EPID600 Final Project"
author: "Emily E. Moin, MD, MBE"
format: html
editor: visual
number-sections: true
embed-resources: true
---

------------------------------------------------------------------------

## Overview {#sec-overview}

Spirometry is a mainstay of diagnosis and monitoring for many pulmonary diseases. Although spirometry encodes a large amount of data with thousands of data points per patient, it is typically interpreted only via a small number of conventional measurements (e.g., forced vital capacity \[FVC\]) and, less commonly, subjective evaluation of the flow-volume loop. By leveraging the spirometry data in the National Health and Nutrition Examination Survey (NHANES), we can develop a proof-of-concept deep learning model to motivate development and inference at larger scale.

## Introduction {#sec-introduction}

As compared to other fields of medicine, pulmonary disease is often more subjective and less algorithmic in its approach to disease diagnosis and monitoring. Although this can be beneficial at times as expert clinicians may leverage "gestalt" judgments for patients' benefit, it also has significant downsides. Among them: the range of individual clinician expertise across a broad swath of uncommon pulmonary diseases can lead to delays in diagnosis and appropriate treatment; ambiguity in disease definitions can make it difficult to appropriately define and recruit populations for clinical trials; and reliance on late manifestations of disease for diagnosis -- like marked reductions in exercise capacity, grossly abnormal pulmonary function tests, and parenchymal changes detectable at the resolution of CT scans -- may shorten the window in which patients can benefit from disease-modifying therapies.

One area for potential advancement in addressing these issues is interpretation of spirometry. Spirometry is one component of "pulmonary function testing" (PFT), an array of tests in which patients actively participate in breathing maneuvers to elicit measurements of pulmonary function and behavior. In spirometry, patients are coached to maximally inhale and then forcefully exhale while the resulting air flow is measured. Although these maneuvers yield a time-series of flow measurements with thousands of data points, a typical PFT report summarizes spirometry into only a few discrete measurements. We hypothesize that there is more meaningful information about pulmonary function and disease encoded into these rich quantitative data sets than is captured by current, conventional pulmonary function measurements. By developing a deep learning model to interpret waveform spirometry data as collected in the National Health and Nutrition Examination Survey (NHANES), we will leverage techniques from machine learning and computer science; methods of inference from biostatistics and epidemiology to assess the model's performance; and domain specific knowledge from pulmonary medicine to ensure the model is fit for purpose and identify next steps in discovery. Although the NHANES cohort is relatively small, demonstrating that a model trained on these data can glean clinically relevant data will provide the motivation for future inquiries training and externally validating in larger data sets.

## Methods {#sec-methods}

We used data collected during the NHANES 2007-2008, 2009-2010, and 2011-2012 cohorts. During this period, NHANES participants without exclusion criteria completed spirometry, which is available in the form of raw flow-time data as well as conventional discrete measurements. We supplemented these data with additional NHANES demographic and questionnaire data for the purposes of model training and outcomes.

First, we load relevant packages for data cleaning and analysis.

```{r Load libraries and set seed}
#| output: false
library(tidyverse)
library(haven)
library(here)
library(mgcv)
library(tidymodels)
library(tableone)
library(ggsci)

set.seed(36)
```

Raw spirometry data from NHANES are available in .sas7bdat files, which are loaded using the read_sas method from the haven package.

```{r Load spirometry data}
spirometry1 <- read_sas(here::here("data/spxraw_e.sas7bdat"))
spirometry2 <- read_sas(here::here("data/spxraw_f.sas7bdat"))
spirometry3 <- read_sas(here::here("data/spxraw_g.sas7bdat"))

all_spirometry <- bind_rows(spirometry1, spirometry2, spirometry3)
rm(spirometry1,spirometry2,spirometry3)

all_spirometry <- all_spirometry %>% dplyr::rename(seqn = SEQN)
```

Additional NHANES data are laoded from relevant .XPT files, cleaned, renamed, and readied for joining.

```{r Load demographic data}
demo1 <- read_xpt(here::here("data/DEMO_E.XPT"))
demo2 <- read_xpt(here::here("data/DEMO_F.XPT"))
demo3 <- read_xpt(here::here("data/DEMO_G.XPT"))

# The demographic variables are different across NHANES years
# so for now I will create a subset with only variables of interest to me

demo1 <- demo1 %>% select(SEQN, RIDAGEEX, RIDRETH1, RIAGENDR)
demo2 <- demo2 %>% select(SEQN, RIDAGEEX, RIDRETH1, RIAGENDR)
demo3 <- demo3 %>% select(SEQN, RIDEXAGM, RIDRETH1, RIAGENDR) %>%
  rename(RIDAGEEX = RIDEXAGM)

all_demo <- bind_rows(demo1, demo2, demo3)
rm(demo1, demo2, demo3)

all_demo <-
  all_demo %>% rename(
  seqn = SEQN,
  age_months = RIDAGEEX,
  gender = RIAGENDR,
  race = RIDRETH1
)

all_demo <- all_demo %>%
  mutate(age_years = floor(age_months/12),
         gender = factor(gender),
         race = factor(race))

all_demo <- all_demo %>%
  mutate(race = factor(race, labels = c("Mexican-American",
                                        "Other Hispanic",
                                        "Non-Hispanic White",
                                        "Non-Hispanic Black",
                                        "Other Race - Including Multi-Racial")))

all_demo <- all_demo %>%
  mutate(gender = factor(gender, labels = c("Male","Female")))

```

```{r Load PFT measurements}
pft1 <- read_xpt(here::here("data/SPX_E.xpt"))
pft2 <- read_xpt(here::here("data/SPX_F.xpt"))
pft3 <- read_xpt(here::here("data/SPX_G.xpt"))

all_pft <- bind_rows(pft1, pft2, pft3)
rm(pft1, pft2, pft3)

all_pft <- 
  all_pft %>% 
  rename(seqn = SEQN) %>%
  rename(fev1 = SPXNFEV1,
         fvc = SPXNFVC,
         fef257 = SPXNF257,
         pef = SPXNPEF) %>%
  mutate(f_ratio = fev1/fvc)
```

```{r Load medical questionnaires}

mcq1 <- read_xpt(here::here("data/MCQ_E.xpt")) %>%
  select(SEQN, MCQ010, MCQ035, MCQ040, MCQ050, MCQ051, MCQ300B, MCQ160G, MCQ160K)
mcq2 <- read_xpt(here::here("data/MCQ_F.xpt")) %>%
  select(SEQN, MCQ010, MCQ035, MCQ040, MCQ050, MCQ051, MCQ300B, MCQ160G, MCQ160K)
mcq3 <- read_xpt(here::here("data/MCQ_G.xpt")) %>%
  select(SEQN, MCQ010, MCQ035, MCQ040, MCQ050, MCQ051, MCQ300B, MCQ160G, MCQ160K)

all_mcq <- bind_rows(mcq1, mcq2, mcq3)
rm(mcq1, mcq2, mcq3)

all_mcq <- all_mcq %>% rename(seqn = SEQN, 
                              ever_asthma = MCQ010,
                              still_asthma = MCQ035,
                              asthma_this_year = MCQ040,
                              asthma_ed_this_year = MCQ050,
                              asthma_rx = MCQ051,
                              family_asthma = MCQ300B,
                              ever_emphysema = MCQ160G,
                              ever_bronchitis = MCQ160K)

# Dichotomize values so that 1=Yes and 0=No or missing
all_mcq <- all_mcq %>%
  mutate(across(-all_of("seqn"), ~ case_when(
    . == 1 ~ 1,
    TRUE ~ 0
  )))

```

```{r Load respiratory health questionnaire}

rh1 <- read_xpt(here::here("data/RDQ_E.xpt")) %>%
  select(SEQN,RDQ070,RDQ080,RDQ100)
rh2 <- read_xpt(here::here("data/RDQ_F.xpt")) %>%
  select(SEQN,RDQ070,RDQ080,RDQ100)
rh3 <- read_xpt(here::here("data/RDQ_G.xpt")) %>%
  select(SEQN,RDQ070,RDQ080,RDQ100)

all_rh <- bind_rows(rh1, rh2, rh3)
rm(rh1, rh2, rh3)

all_rh <- all_rh %>% rename(seqn = SEQN,
                            wheeze_bin = RDQ070,
                            wheeze_count = RDQ080,
                            wheeze_exercise = RDQ100)

# Dichotomize values so that 1=Yes and 0=No or missing
all_rh <- all_rh %>%
  mutate(across(c(wheeze_bin, wheeze_exercise), ~ case_when(
    . == 1 ~ 1,
    TRUE ~ 0
  )))

# Retain count values and set all other values to 0
all_rh <- all_rh %>%
  mutate(wheeze_count = case_when(
    wheeze_count > 0 & wheeze_count <= 12 ~ wheeze_count,
    TRUE ~ 0
  ))

```

Now that all relevant data are loaded, we can apply inclusion and exclusion criteria to develop our study cohort. We will limit to adult patients (age 18 and over), apply some high-level quality control on the included spirometry curves, and filter our dataset to include only one raw spirometry curve per participant. This step is important because failing to correctly split the cohort between training and validation sets -- i.e., allowing one participant's data to appear in both sets -- would lead to data leakage that could falsely inflate the observed performance of the model. This also spares us from needing to consider clustering when we performance inference. Finally, we drop records where useful variables are missing -- i.e., we will use complete case analysis for this proof-of-concept study design.

```{r Cohort derivation}

# To identify cohort, we will filter on inclusion criteria (age >=18) and
# clean raw spirometry samples - remaining patient IDs will then be
# used to filter all other tables

# Store number of patients at every step of filtering for future study
# flowchart
update_patient_list <- function(included, step, n) {
  
  included <- included %>% add_row(
    step = step,
    included_n = n
  )
  
  return(included)
  
}

included_patients <- tibble(
  step = "initial",
  included_n = all_spirometry %>% count(seqn) %>% nrow()
)

# Exclude children
adult_demo <- all_demo %>%
  filter(age_years >= 18)

all_spirometry <- 
  all_spirometry %>%
  filter(seqn %in% adult_demo$seqn)

included_patients <- 
  update_patient_list(included_patients,
                      "age >= 18", all_spirometry %>% count(seqn) %>% nrow())

# Exclude maneuvers that are "too short"
# Based on exploratory analyses, deep learning model performs well
# with spirometry curves of length 256 (2.56 sec), so exclude samples
# that are shorter than this
all_spirometry <-
  all_spirometry %>%
  filter(SPXPTS >=256)

included_patients <- 
  update_patient_list(included_patients,
                      "at least 2.56 sec", all_spirometry %>% count(seqn) %>% nrow())

# Exclude post-bronchodilator curves - these are obtained under specific
# diagnostic contexts and may bias our model in unexpected ways. Note - it may
# seem non-intuitive that this would reduce the n since no patients have ONLY
# post-bronchodilator curves, however patients who are dropped at this step may
# have had pre-bronchodilator curves that were already filtered for other
# quality reasons

all_spirometry <-
  all_spirometry %>%
  filter(SPATTYPE=="Pre")

included_patients <- 
  update_patient_list(included_patients,
                      "exclude BD testing", all_spirometry %>% count(seqn) %>% nrow())

# Limit to one curve per patient chosen at random to prevent data leakage
all_spirometry <- all_spirometry %>%
  group_by(seqn) %>%
  slice_sample(n = 1) %>%
  ungroup()

# Save data to CSV for import into deep learning model
regression_data <-
  all_spirometry %>%
  left_join(all_pft, by = "seqn") %>%
  left_join(all_mcq, by = "seqn") %>%
  left_join(all_rh, by = "seqn") %>%
  left_join(all_demo, by = "seqn") %>%
  select(seqn, SPXRAW, ever_asthma, 
         still_asthma, asthma_this_year, asthma_ed_this_year,
         asthma_rx, family_asthma, ever_emphysema, ever_bronchitis,
         gender, age_months, age_years, race,
         wheeze_bin, wheeze_exercise, wheeze_count,
         fev1, fvc, f_ratio, fef257, pef) %>%
  mutate(
    ever_asthma = factor(ever_asthma),
    asthma_this_year = factor(asthma_this_year),
    asthma_ed_this_year = factor(asthma_ed_this_year),
    asthma_rx = factor(asthma_rx),
    family_asthma = factor(family_asthma),
    wheeze_bin = factor(wheeze_bin),
    wheeze_exercise = factor(wheeze_exercise)
  ) %>%
  drop_na() %>%
  write_csv(here::here("data/complete_resnet_multi_v256.csv"))

```

Now that the data are cleaned and exported, they can be imported into our Python development environment for model development and training. Our deep learning model is a convolutional neural network built on a ResNet-9 architecture using the PyTorch library. It takes as input two channels of 1-dimensional input data -- a flow-time channel, as provided by NHANES, and a volume-time channel, calculated as the cumulative sum of the flow-time data -- and returns as output predictions for a regression or classification task.

As a proof-of-concept, we choose a clinically-relevant, non-trivial classification task with a label that is available in NHANES: prevalent asthma diagnosis (encoded by "ever_asthma" in our dataset). Recognizing prevalent asthma is clearly clinically relevant, as patients with asthma require monitoring, prevention and treatment for exacerbated disease. It is non-trivial in the sense that asthma is a clinical diagnosis that cannot be ruled either in or out based on spirometry measurements alone (in contrast to, e.g., chronic obstructive pulmonary disease, which requires a spirometry-based threshold). Although spirometry is frequently obtained in the diagnosis of asthma, patients with asthma often have "normal" spirometry based on conventional measurements and may require additional specialized testing (spirometry with bronchodilator or bronchoprovocation testing).

In the Python environment, the exported data are randomly divided into an 80/20 training/validation split. After the model is trained, model output (predictions of prevalent asthma) are exported for the validation samples only and imported back into R for inference.

```{r Regression data}
# Data are sent to deep learning model

# Load predictions from deep learning model
# This file contains validation set only - we will use this as source of
# truth for training/validation split
dl_outputs <- read_csv(here::here("data/validation_predictions_256_6710.csv"),
                       show_col_types = FALSE)

# Use dl_outputs to add a column to regression_data indicating
# training/validation split - this ensures that all of our models are trained
# on the same training data and validated on the same validation data
regression_data <-
  regression_data %>%
  mutate(validation = case_when(
    seqn %in% dl_outputs$seqn ~ 1,
    .default = 0
  ))
```

Our hypothesis is that deep learning will facilitate better predictive performance for prevalent asthma than conventional PFT measurements. Therefore, for our comparators we develop models that take as input the four most commonly used conventional PFT measurements in the characterization of asthma:

1. Forced expiratory volume in 1 second (FEV1), 
2. Forced vital capacity (FVC), 
3. Forced mid-expiratory flow (FEF25-75), and
4. Ratio of FEV1 to FVC (FEV1/FVC). 

Using the same 80/20 training/validation split, we develop: 

1. Generalized linear model: a logistic regression model with the binary outcome of ever_asthma and one term for each of the four conventional measurements. This model is straightforward and easily interpretable, however, it is possible that it is too inflexible to capture the full clinically-relevant data encoded in the four conventional measurements. Therefore, as a more robust comparator, we also develop:
2. Generalized additive model (GAM) with cubic splines applied to each conventional measurement. This allows more flexibility, reducing the likelihood that failure to capture variation in prevalent asthma is due to model misspecification.

```{r Train alternative models}
# Train GLM on training records only
m0 <- glm(
  ever_asthma ~ 
    fev1 +
    fvc +
    f_ratio +
    fef257,
  data = filter(regression_data,validation==0),
  family = "binomial"
)

# Generate predicted probabilities on validation records only
preds <- predict.glm(
  m0, newdata = filter(regression_data,validation==1),
  type="response"
) %>% as_tibble_col(column_name = "pred")

# Format for yardstick
glm_validation_data <-
  regression_data %>%
  filter(validation==1) %>%
  bind_cols(
    ., preds
  ) %>%
  mutate(ever_asthma = factor(ever_asthma)) %>%
  mutate(group = "glm") %>%
  select(seqn, ever_asthma, pred, group)

# Train GAM on training records only
m0 <- gam(
  ever_asthma ~ 
    s(fev1,bs="cr") + 
    s(fvc,bs="cr") + 
    s(f_ratio,bs="cr") + 
    s(fef257,bs="cr"),
  data = filter(regression_data,validation==0),
  family = "binomial"
)

# Generate predicted probabilities on validation records only
preds <- predict.gam(
  m0, newdata = filter(regression_data,validation==1),
  type="response"
) %>% as_tibble_col(column_name = "pred")

# Format for yardstick
gam_validation_data <-
  regression_data %>%
  filter(validation==1) %>%
  bind_cols(
    ., preds
  ) %>%
  mutate(ever_asthma = factor(ever_asthma)) %>%
  mutate(group = "gam") %>%
  select(seqn, ever_asthma, pred, group)
```

Finally, we format the predictions from our deep learning model similarly in preparation to use the yardstick package for model evaluation.

```{r Prepare deep learning data}
# Format DL predictions for yardstick
dl_validation_data <-
  dl_outputs %>%
  rename(pred = classification_3_probs) %>%
  left_join(regression_data, by = "seqn") %>%
  select(seqn, ever_asthma, pred) %>%
  mutate(group = "dl") %>%
  mutate(ever_asthma = factor(ever_asthma))
```


```{r Combine model validation data}

combined_validation_data <-
  bind_rows(gam_validation_data, glm_validation_data, dl_validation_data)

```

## Results {#sec-results}

```{r Create Table 1}

vars = c("gender", "age_years", "race", "ever_asthma", "asthma_rx", "family_asthma",
         "wheeze_bin", "wheeze_exercise",
         "fev1", "fvc", "f_ratio", "fef257")

tableOne <- CreateTableOne(vars = vars, data = regression_data)

print(tableOne)

```
Our combined cohort (training and validation) includes 9,841 adult patients with mean age 44.71 (SD 17.47). Our cohort reflects the weighted-sample demographics of NHANES, with 49.8% female subjects, 19.9% non-Hispanic Black and 45.2% non-Hispanic white participants. Of note, we do not apply NHANES demographic sampling weights to our analysis as it is not performed for descriptive epidemiologic purposes. In this cohort, 13.6% of participants reported prevalent asthma (a diagnosis of asthma ever prior to NHANES inclusion), 4.8% a current prescription for asthma treatment, 20.4% a family history of asthma, 13.0% a history of wheezing, and 5.9% wheezing with exercise. FEV1, FVC, and FEF257 are reported in mL and reflect typical population distributions.

```{r}
# Calculate AUROC values
combined_validation_data %>%
  group_by(group) %>%
  roc_auc(
    truth = ever_asthma,
    pred,
    event_level = "second" 
  )
```

Comparing absolute AUROC values, we find that the models trained on conventional PFT measurements have some discriminative capability, but it is relatively poor, consistent with what we know about how asthma diagnoses are made clinically. Unsurprisingly, the more flexible GAM performs slightly better with an AUROC of 0.62 as compared to the GLM's AUROC of 0.61. Our deep learning model performs considerably better, achieving an AUROC of 0.67. We can visualize this graphically as well:

```{r}
# Generate ROC curve figure
combined_validation_data %>%
  group_by(group) %>%
  roc_curve(
    truth = ever_asthma,
    pred,
    event_level = "second"
  ) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, group = group)) +
  geom_path(aes(color = group)) +
  geom_abline(lty = 3) +
  coord_equal() +
  theme_bw() +
  scale_colour_jama(
    name = "Model",
    limits = c("dl",
               "gam",
               "glm"),
    labels = c("DL","GAM","GLM")
  ) +
  ggtitle("ROC curve for prevalent asthma")
```
Thus, we demonstrate that applying deep learning to raw spirometry data markedly improves discrimination for the task of identifying prevalent asthma over the use of discrete, conventional PFT measurements.

## Conclusion

In this small, proof-of-concept design we demonstrate the opportunity to unlock clinically-relevant data concerning pulmonary disease by applying deep learning to raw spirometry data, with value over-and-above what is currently available through the use of conventional PFT measurements. Given NHANES's relatively small cohort size and coarse associated data -- notably lacking longitudinal or follow up data -- we consider these results to be a pessimistic reflection of what is possible when deep learning is applied to a richer, more clinically-oriented dataset. Future work will externally validate these results in other cohorts and develop more clinically-relevant models by incorporating longitudinal patient data from the electronic health record (e.g., predicting asthma exacerbation requiring hospital admission).